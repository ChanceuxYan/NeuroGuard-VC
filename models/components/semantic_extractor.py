# models/components/semantic_extractor.py
import torch
import torch.nn as nn
import os
from transformers import Wav2Vec2Model, HubertModel

class SemanticExtractor(nn.Module):
    def __init__(self, model_type='hubert', model_name=None, freeze=True, unfreeze_last_n_layers=0):
        super().__init__()
        self.model_type = model_type
        
        # 1. è·¯å¾„åŠ è½½é€»è¾‘ (ä¿æŒä¸å˜)
        target_bin_path = "/home/yanjunzhe/project/WM-V2/NeuroGuard-VC/hubert/pytorch_model.bin"
        target_dir = os.path.dirname(target_bin_path)
        
        if os.path.exists(target_bin_path):
            final_model_path = target_dir
            print(f"âœ… Found local model at: {target_bin_path}")
        elif model_name is None:
            # å›é€€é€»è¾‘
            project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            default_local = os.path.join(project_root, "hubert")
            if os.path.exists(os.path.join(default_local, "pytorch_model.bin")):
                final_model_path = default_local
            else:
                final_model_path = "facebook/hubert-large-ls960-ft"
        else:
            final_model_path = model_name

        print(f"Loading Semantic Model from: {final_model_path}")

        # 2. åŠ è½½æ¨¡å‹
        if model_type == 'hubert':
            try:
                self.model = HubertModel.from_pretrained(final_model_path)
            except Exception as e:
                print(f"âš  HubertModel load failed, trying Wav2Vec2Model: {e}")
                self.model = Wav2Vec2Model.from_pretrained(final_model_path)
        elif model_type == 'wav2vec2':
            self.model = Wav2Vec2Model.from_pretrained(final_model_path)
        else:
            raise ValueError(f"Unsupported model_type: {model_type}")

        # 3. [å…³é”®] å…è®¸æ¢¯åº¦å›ä¼ é…ç½®
        self.model.config.freeze_feature_encoder = False 
        self.model.config.feat_proj_dropout = 0.0
        self.model.config.attention_dropout = 0.0
        self.model.config.hidden_dropout = 0.0
        self.model.config.activation_dropout = 0.0
        self.model.config.mask_time_prob = 0.0
        self.model.config.layerdrop = 0.0

        # 4. [å…³é”®] å†»ç»“ä¸ç­–ç•¥æ€§è§£å†»
        if freeze:
            self.model.eval()
            for param in self.model.parameters():
                param.requires_grad = False
            
            # === æ–°å¢é€»è¾‘ï¼šè§£å†»æœ€å N å±‚ ===
            if unfreeze_last_n_layers > 0 and hasattr(self.model, 'encoder'):
                print(f"ğŸ”“ Unfreezing the last {unfreeze_last_n_layers} layers of Semantic Model...")
                layers = self.model.encoder.layers
                # è§£å†»æœ€å N å±‚ Transformer Encoder
                for i in range(1, unfreeze_last_n_layers + 1):
                    for param in layers[-i].parameters():
                        param.requires_grad = True

    def train(self, mode=True):
        # å§‹ç»ˆä¿æŒåº•å±‚æ¨¡å‹ä¸º eval æ¨¡å¼ (å³ä½¿éƒ¨åˆ†å±‚è§£å†»ï¼ŒBN/Dropout ä¹Ÿä¸è¦åŠ¨)
        super().train(False) 
        self.model.eval()
        return self

    def forward(self, waveform):
        if waveform.dim() == 3:
            waveform = waveform.squeeze(1)
            
        # PyTorch åŸç”Ÿå½’ä¸€åŒ– (ä¿ç•™æ¢¯åº¦)
        with torch.set_grad_enabled(True):
            mean = waveform.mean(dim=-1, keepdim=True)
            std = waveform.std(dim=-1, keepdim=True)
            input_values = (waveform - mean) / (std + 1e-7)
        
        outputs = self.model(input_values)
        features = outputs.last_hidden_state
        features = features.transpose(1, 2)
        return features

    def get_feature_dim(self):
        return self.model.config.hidden_size