2025-12-08 19:18:19 - ================================================================================
2025-12-08 19:18:19 - NeuroGuard-VC 训练开始
2025-12-08 19:18:19 - 配置文件: configs/vctk_16k.yaml
2025-12-08 19:18:19 - 设备: cuda:3
2025-12-08 19:18:19 - ================================================================================
2025-12-08 19:18:19 - 训练集大小: 35715
2025-12-08 19:18:19 - 验证集大小: 8740
2025-12-08 19:18:19 - Checkpoint目录: checkpoints
2025-12-08 19:18:19 - ================================================================================
2025-12-08 19:18:19 - Epoch 1/200 [Training Stage: stage1 (λ_msg=100.0)]
2025-12-08 19:18:19 - ================================================================================
2025-12-08 19:19:22 - Epoch 1/200, Step 200/4465
2025-12-08 19:19:22 -   Loss_G: 63.1993, Loss_D: 1.4358
2025-12-08 19:19:22 -   STFT: 6.8853, Loc: 0.0403, Msg: 0.6319
2025-12-08 19:19:22 -   Acc: 0.520
2025-12-08 19:19:22 -   Sem: 0.1028
2025-12-08 19:19:22 - --------------------------------------------------------------------------------
2025-12-08 19:20:23 - Epoch 1/200, Step 400/4465
2025-12-08 19:20:23 -   Loss_G: 62.0627, Loss_D: 1.3893
2025-12-08 19:20:23 -   STFT: 7.0181, Loc: 0.0273, Msg: 0.6205
2025-12-08 19:20:23 -   Acc: 0.533
2025-12-08 19:20:23 -   Sem: 0.1025
2025-12-08 19:20:23 - --------------------------------------------------------------------------------
2025-12-08 19:21:24 - Epoch 1/200, Step 600/4465
2025-12-08 19:21:24 -   Loss_G: 61.3514, Loss_D: 1.3429
2025-12-08 19:21:24 -   STFT: 7.0759, Loc: 0.0183, Msg: 0.6134
2025-12-08 19:21:24 -   Acc: 0.545
2025-12-08 19:21:24 -   Sem: 0.1026
2025-12-08 19:21:24 - --------------------------------------------------------------------------------
2025-12-08 19:22:25 - Epoch 1/200, Step 800/4465
2025-12-08 19:22:25 -   Loss_G: 60.9513, Loss_D: 1.3265
2025-12-08 19:22:25 -   STFT: 7.0343, Loc: 0.0146, Msg: 0.6094
2025-12-08 19:22:25 -   Acc: 0.552
2025-12-08 19:22:25 -   Sem: 0.1013
2025-12-08 19:22:25 - --------------------------------------------------------------------------------
2025-12-08 19:23:26 - Epoch 1/200, Step 1000/4465
2025-12-08 19:23:26 -   Loss_G: 60.6626, Loss_D: 1.2993
2025-12-08 19:23:26 -   STFT: 7.0147, Loc: 0.0117, Msg: 0.6066
2025-12-08 19:23:26 -   Acc: 0.557
2025-12-08 19:23:26 -   Sem: 0.1012
2025-12-08 19:23:26 - --------------------------------------------------------------------------------
2025-12-08 19:24:27 - Epoch 1/200, Step 1200/4465
2025-12-08 19:24:27 -   Loss_G: 60.4098, Loss_D: 1.3383
2025-12-08 19:24:27 -   STFT: 6.9903, Loc: 0.0097, Msg: 0.6040
2025-12-08 19:24:27 -   Acc: 0.560
2025-12-08 19:24:27 -   Sem: 0.1018
2025-12-08 19:24:27 - --------------------------------------------------------------------------------
2025-12-08 19:25:28 - Epoch 1/200, Step 1400/4465
2025-12-08 19:25:28 -   Loss_G: 60.1944, Loss_D: 1.3180
2025-12-08 19:25:28 -   STFT: 6.9957, Loc: 0.0083, Msg: 0.6019
2025-12-08 19:25:28 -   Acc: 0.564
2025-12-08 19:25:28 -   Sem: 0.1019
2025-12-08 19:25:28 - --------------------------------------------------------------------------------
2025-12-08 19:26:30 - Epoch 1/200, Step 1600/4465
2025-12-08 19:26:30 -   Loss_G: 59.9698, Loss_D: 1.2912
2025-12-08 19:26:30 -   STFT: 6.9901, Loc: 0.0073, Msg: 0.5996
2025-12-08 19:26:30 -   Acc: 0.568
2025-12-08 19:26:30 -   Sem: 0.1022
2025-12-08 19:26:30 - --------------------------------------------------------------------------------
2025-12-08 19:27:31 - Epoch 1/200, Step 1800/4465
2025-12-08 19:27:31 -   Loss_G: 59.7546, Loss_D: 1.3438
2025-12-08 19:27:31 -   STFT: 6.9747, Loc: 0.0065, Msg: 0.5975
2025-12-08 19:27:31 -   Acc: 0.571
2025-12-08 19:27:31 -   Sem: 0.1022
2025-12-08 19:27:31 - --------------------------------------------------------------------------------
2025-12-08 19:28:32 - Epoch 1/200, Step 2000/4465
2025-12-08 19:28:32 -   Loss_G: 59.5619, Loss_D: 1.2945
2025-12-08 19:28:32 -   STFT: 6.9458, Loc: 0.0058, Msg: 0.5956
2025-12-08 19:28:32 -   Acc: 0.574
2025-12-08 19:28:32 -   Sem: 0.1024
2025-12-08 19:28:32 - --------------------------------------------------------------------------------
2025-12-08 19:29:33 - Epoch 1/200, Step 2200/4465
2025-12-08 19:29:33 -   Loss_G: 59.3814, Loss_D: 1.2855
2025-12-08 19:29:33 -   STFT: 6.9349, Loc: 0.0053, Msg: 0.5938
2025-12-08 19:29:33 -   Acc: 0.576
2025-12-08 19:29:33 -   Sem: 0.1020
2025-12-08 19:29:33 - --------------------------------------------------------------------------------
2025-12-08 19:30:34 - Epoch 1/200, Step 2400/4465
2025-12-08 19:30:34 -   Loss_G: 59.2186, Loss_D: 1.2507
2025-12-08 19:30:34 -   STFT: 6.9243, Loc: 0.0049, Msg: 0.5921
2025-12-08 19:30:34 -   Acc: 0.578
2025-12-08 19:30:34 -   Sem: 0.1022
2025-12-08 19:30:34 - --------------------------------------------------------------------------------
2025-12-08 19:31:35 - Epoch 1/200, Step 2600/4465
2025-12-08 19:31:35 -   Loss_G: 59.0596, Loss_D: 1.2873
2025-12-08 19:31:35 -   STFT: 6.9244, Loc: 0.0045, Msg: 0.5905
2025-12-08 19:31:35 -   Acc: 0.580
2025-12-08 19:31:35 -   Sem: 0.1023
2025-12-08 19:31:35 - --------------------------------------------------------------------------------
2025-12-08 19:32:37 - Epoch 1/200, Step 2800/4465
2025-12-08 19:32:37 -   Loss_G: 58.8949, Loss_D: 1.2625
2025-12-08 19:32:37 -   STFT: 6.9145, Loc: 0.0042, Msg: 0.5889
2025-12-08 19:32:37 -   Acc: 0.582
2025-12-08 19:32:37 -   Sem: 0.1027
2025-12-08 19:32:37 - --------------------------------------------------------------------------------
2025-12-08 19:33:38 - Epoch 1/200, Step 3000/4465
2025-12-08 19:33:38 -   Loss_G: 58.7225, Loss_D: 1.2308
2025-12-08 19:33:38 -   STFT: 6.9099, Loc: 0.0039, Msg: 0.5872
2025-12-08 19:33:38 -   Acc: 0.584
2025-12-08 19:33:38 -   Sem: 0.1029
2025-12-08 19:33:38 - --------------------------------------------------------------------------------
2025-12-08 19:34:39 - Epoch 1/200, Step 3200/4465
2025-12-08 19:34:39 -   Loss_G: 58.5703, Loss_D: 1.2515
2025-12-08 19:34:39 -   STFT: 6.9064, Loc: 0.0037, Msg: 0.5856
2025-12-08 19:34:39 -   Acc: 0.586
2025-12-08 19:34:39 -   Sem: 0.1030
2025-12-08 19:34:39 - --------------------------------------------------------------------------------
